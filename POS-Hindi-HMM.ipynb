{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.1 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import indian\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[('यह', 'DEM'), ('एशिया', 'NNP'), ('की', 'PSP'), ('सबसे', 'INTF'), ('बड़ी', 'JJ'), ('मस्जिदों', 'NN'), ('में', 'PSP'), ('से', 'PSP'), ('एक', 'QC'), ('है', 'VM'), ('।', 'SYM')], [('इसे', 'PRP'), ('नवाब', 'NN'), ('शाहजेहन', 'NNP'), ('ने', 'PSP'), ('बनवाया', 'VM'), ('था', 'VAUX'), ('।', 'SYM')], [('इसका', 'PRP'), ('प्रवेश', 'NN'), ('द्वार', 'NN'), ('दो', 'QC'), ('मंजिला', 'JJ'), ('है', 'VM'), ('।', 'SYM')]]\n"
     ]
    }
   ],
   "source": [
    "wordtag_dataset= []\n",
    "try:\n",
    "\t# read the training data file #\n",
    "    input_file = codecs.open(\"dataset.txt\", mode = 'r', encoding=\"utf-8\")\n",
    "    lines = input_file.readlines()\n",
    "    # pushing words of a line into a list #\n",
    "    for line in lines:\n",
    "        line = line.rstrip()\n",
    "        data = line.split(\" \")\n",
    "        # word,tag=data.split(\"/\")\n",
    "        wordtag_list=[]\n",
    "        for wordtag in data:\n",
    "            try:\n",
    "                word,tag=wordtag.split(\"/\")\n",
    "                wordtag_list.append((word,tag))\n",
    "            except:\n",
    "                pass\n",
    "        wordtag_dataset.append(wordtag_list)\n",
    "        \n",
    "    input_file.close()\n",
    "except IOError:\n",
    "    fo = codecs.open(output_file,mode = 'w',encoding=\"utf-8\")\n",
    "    fo.write(\"File not found: {}\".format(fin))\n",
    "    fo.close()\n",
    "    sys.exit()\n",
    "print(wordtag_dataset[:3])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[('पूर्ण', 'JJ'), ('प्रतिबंध', 'NN'), ('हटाओ', 'VFM'), (':', 'SYM'), ('इराक', 'NNP')], [('संयुक्त', 'NNC'), ('राष्ट्र', 'NN'), ('।', 'SYM')]]\n"
     ]
    }
   ],
   "source": [
    "hindi_tagged_data = list(indian.tagged_sents('hindi.pos'))\n",
    "print(hindi_tagged_data[:2])\n",
    "tagged_data =[ [ tuple for tuple in sent if tuple[1]!=''] for sent in hindi_tagged_data] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and validation set in the ratio 80:20\n",
    "train_set,test_set =train_test_split(wordtag_dataset,train_size=0.86,test_size=0.14,random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12869\n2095\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "272589\n43685\n"
     ]
    }
   ],
   "source": [
    "# create list of train and test tagged words\n",
    "train_tagged_words = [ tup for sent in train_set for tup in sent ]\n",
    "test_tagged_words = [ tup for sent in test_set for tup in sent ]\n",
    "print(len(train_tagged_words))\n",
    "print(len(test_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('सम्मेलन', 'NN'),\n",
       " ('की', 'PSP'),\n",
       " ('अध्यक्षता', 'NN'),\n",
       " ('कर', 'VM'),\n",
       " ('रहे', 'VAUX')]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "train_tagged_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "25\n{'NN', 'RDP', 'RB', 'SYM', 'NEG', 'QO', 'QFC', 'INJ', 'CC', 'PSP', 'INTF', 'VAUX', 'NNP', 'RP', 'QC', 'UNK', 'PRP', 'WQ', 'PRPC', 'RBC', 'JJ', 'DEM', 'VM', 'QF', 'NST'}\n"
     ]
    }
   ],
   "source": [
    "#use set datatype to check how many unique tags are present in training data\n",
    "tags = {tag for word,tag in train_tagged_words}\n",
    "print(len(tags))\n",
    "print(tags)\n",
    " \n",
    "# check total words in vocabulary\n",
    "vocab = {word for word,tag in train_tagged_words}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)                           #total number of times the passed tag occurred in train_bag\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    \n",
    "    #now calculate the total number of times the passed word occurred as the passed tag.\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1.16908260e-01 0.00000000e+00 3.59081291e-03 1.83843002e-02\n  1.59352664e-02 3.47498019e-04 4.96425746e-05 0.00000000e+00\n  2.33320091e-02 4.87738281e-01 7.94281194e-04 0.00000000e+00\n  5.43255247e-02 1.48100341e-02 7.08234031e-03 8.10828700e-04\n  1.12026744e-02 1.00939895e-03 9.92851492e-05 6.61900995e-05\n  3.79765704e-02 3.62390792e-03 1.94019720e-01 3.72319296e-03\n  4.16997634e-03]\n [4.30939227e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 1.16022103e-01 0.00000000e+00 2.76243091e-02\n  5.52486181e-02 2.20994484e-02 3.86740342e-02 0.00000000e+00\n  2.76243091e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  9.39226523e-02 1.65745858e-02 1.60220996e-01 5.52486209e-03\n  5.52486209e-03]\n [2.60944217e-01 6.00858359e-03 1.71673822e-03 5.83691001e-02\n  1.11587979e-02 5.15021477e-03 0.00000000e+00 0.00000000e+00\n  8.58369109e-04 6.86695287e-03 0.00000000e+00 0.00000000e+00\n  1.08154505e-01 1.32188842e-01 3.09012868e-02 8.58369109e-04\n  6.86695278e-02 1.71673822e-03 0.00000000e+00 0.00000000e+00\n  1.09871246e-01 3.34763937e-02 1.46781117e-01 1.20171672e-02\n  4.29184549e-03]\n [2.08749384e-01 9.32310894e-03 1.36260828e-02 6.01312937e-03\n  0.00000000e+00 3.75131029e-03 5.51663252e-05 1.10332650e-04\n  6.50962666e-02 2.37766858e-02 3.30997951e-04 5.51663252e-05\n  3.19909513e-01 3.08931433e-03 1.98047105e-02 1.10332650e-04\n  1.82600543e-01 1.43432454e-03 2.20665301e-04 0.00000000e+00\n  6.38274401e-02 5.67661487e-02 7.66811939e-03 7.61295296e-03\n  6.01312937e-03]\n [2.88517028e-03 0.00000000e+00 5.77034021e-04 7.50144245e-03\n  5.77034021e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  2.88517028e-03 0.00000000e+00 0.00000000e+00 1.73110217e-02\n  1.15406804e-03 1.73110212e-03 5.77034021e-04 0.00000000e+00\n  5.77034021e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  6.92440849e-03 5.77034021e-04 9.56722438e-01 0.00000000e+00\n  0.00000000e+00]\n [7.67281115e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  2.76497696e-02 2.30414746e-03 6.91244239e-03 0.00000000e+00\n  4.83870953e-02 4.60829493e-03 6.91244239e-03 0.00000000e+00\n  4.60829493e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  5.06912433e-02 9.21658985e-03 2.30414746e-03 2.30414746e-03\n  6.68202788e-02]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.85714298e-01\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 7.14285746e-02 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.42857134e-01\n  0.00000000e+00]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  6.66666687e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 3.33333343e-01 0.00000000e+00\n  0.00000000e+00]\n [2.70272911e-01 0.00000000e+00 8.44296068e-03 1.72786172e-02\n  4.90869803e-04 3.82878468e-03 9.81739649e-05 0.00000000e+00\n  1.21735716e-02 9.81739649e-05 1.17808755e-03 0.00000000e+00\n  2.80188501e-01 5.30139403e-03 2.80777533e-02 0.00000000e+00\n  1.87414095e-01 5.30139403e-03 3.92695860e-04 0.00000000e+00\n  1.06027879e-01 4.64362837e-02 6.18495978e-03 1.48242684e-02\n  5.98861184e-03]\n [3.72790575e-01 0.00000000e+00 7.34796841e-03 3.50947748e-03\n  2.63210805e-03 3.32669215e-03 1.09671171e-04 1.82785279e-05\n  1.18810439e-03 8.21071491e-02 2.48587993e-03 0.00000000e+00\n  1.02999508e-01 2.35427450e-02 3.95547338e-02 5.30077319e-04\n  4.62263972e-02 1.22466136e-03 3.10734991e-04 1.64506753e-04\n  1.11115173e-01 2.05085091e-02 1.12851635e-01 1.67065747e-02\n  4.87488359e-02]\n [0.00000000e+00 0.00000000e+00 1.00334445e-02 0.00000000e+00\n  0.00000000e+00 3.34448158e-03 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 3.67892981e-02 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  6.75585270e-01 0.00000000e+00 3.34448158e-03 2.70903021e-01\n  0.00000000e+00]\n [2.69215312e-02 0.00000000e+00 8.03627830e-04 4.87170666e-01\n  5.74019869e-05 5.74019869e-05 0.00000000e+00 0.00000000e+00\n  1.04414210e-01 2.30181962e-02 1.72205953e-04 2.93955564e-01\n  1.77946165e-02 1.20544166e-03 3.61632509e-03 5.74019869e-05\n  2.09517255e-02 0.00000000e+00 1.14803974e-04 0.00000000e+00\n  6.02720864e-03 2.98490329e-03 9.47132800e-03 1.03323581e-03\n  1.72205953e-04]\n [6.80533871e-02 0.00000000e+00 9.61885322e-04 6.70313835e-02\n  2.70530232e-04 4.20824828e-04 0.00000000e+00 0.00000000e+00\n  3.67620550e-02 4.12618726e-01 4.50883730e-04 0.00000000e+00\n  3.69574368e-01 5.32042794e-03 2.19430076e-03 1.20235665e-04\n  5.35048684e-03 1.80353498e-04 0.00000000e+00 6.01178326e-05\n  1.24143325e-02 2.28447746e-03 1.46687506e-02 7.81531795e-04\n  4.80942661e-04]\n [2.86174506e-01 0.00000000e+00 6.17449684e-03 4.29530209e-03\n  1.90604031e-02 1.34228193e-03 2.68456381e-04 0.00000000e+00\n  1.07382552e-03 2.89932881e-02 1.61073823e-03 5.63758379e-03\n  8.45637619e-02 4.02684556e-03 9.42281857e-02 1.07382552e-03\n  8.10738280e-02 5.36912761e-04 0.00000000e+00 2.68456381e-04\n  1.36375844e-01 3.03355698e-02 1.68053687e-01 3.03355698e-02\n  1.44966440e-02]\n [6.69245660e-01 1.93423592e-04 0.00000000e+00 1.99226309e-02\n  1.93423592e-04 3.86847183e-04 0.00000000e+00 0.00000000e+00\n  5.41586056e-03 3.77176031e-02 1.35396514e-03 0.00000000e+00\n  1.04448739e-02 5.41586056e-03 1.02901354e-01 0.00000000e+00\n  3.86847183e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  1.20502904e-01 2.12765951e-03 1.58607345e-02 7.54352054e-03\n  3.86847183e-04]\n [1.94174759e-02 0.00000000e+00 0.00000000e+00 9.70873795e-03\n  3.88349518e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  9.70873795e-03 0.00000000e+00 0.00000000e+00 9.70873795e-03\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  2.91262139e-02 0.00000000e+00 8.73786390e-01 0.00000000e+00\n  9.70873795e-03]\n [3.19771081e-01 8.94214463e-05 7.42197968e-03 3.57685774e-03\n  6.88545126e-03 4.73933667e-03 1.78842893e-04 0.00000000e+00\n  2.59322184e-03 1.17499776e-01 3.48743633e-03 0.00000000e+00\n  8.28936771e-02 3.96136977e-02 2.43226327e-02 8.04792973e-04\n  7.88697153e-02 2.14611460e-03 8.94214434e-04 0.00000000e+00\n  9.67539996e-02 2.60216407e-02 1.21792004e-01 1.44862738e-02\n  4.51578274e-02]\n [3.08880299e-01 0.00000000e+00 3.86100379e-03 1.15830116e-02\n  5.40540554e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  3.86100379e-03 3.08880303e-02 0.00000000e+00 3.86100379e-03\n  5.79150580e-02 7.72200758e-03 3.86100379e-03 0.00000000e+00\n  9.26640928e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  4.63320464e-02 1.93050187e-02 3.51351351e-01 0.00000000e+00\n  3.86100379e-03]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 3.60000014e-01\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  6.39999986e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00]\n [0.00000000e+00 0.00000000e+00 3.33333343e-01 5.55555582e-01\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 1.11111112e-01 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00]\n [5.47246397e-01 6.44122410e-05 6.44122410e-05 1.33977458e-02\n  2.10628025e-02 1.93236716e-04 0.00000000e+00 0.00000000e+00\n  1.20450882e-02 0.00000000e+00 1.93236716e-04 0.00000000e+00\n  4.38647345e-02 2.76972633e-03 1.33977458e-02 0.00000000e+00\n  2.64090183e-03 3.86473432e-04 6.44122410e-05 0.00000000e+00\n  3.93558778e-02 2.76972633e-03 2.95265704e-01 3.54267308e-03\n  1.67471822e-03]\n [8.73947322e-01 0.00000000e+00 0.00000000e+00 1.35832652e-03\n  0.00000000e+00 1.62999181e-03 0.00000000e+00 0.00000000e+00\n  0.00000000e+00 0.00000000e+00 8.14995903e-04 0.00000000e+00\n  6.51996722e-03 5.43330610e-03 1.62999183e-02 0.00000000e+00\n  1.41265960e-02 0.00000000e+00 2.71665311e-04 0.00000000e+00\n  4.91714217e-02 0.00000000e+00 0.00000000e+00 8.42162501e-03\n  2.20048893e-02]\n [3.36613171e-02 3.45244262e-05 7.25012971e-04 1.82012767e-01\n  1.89884345e-03 3.45244247e-04 0.00000000e+00 0.00000000e+00\n  1.40963227e-01 1.41446576e-01 3.45244247e-04 4.22648013e-01\n  1.01156570e-02 5.38581051e-03 4.35007783e-03 6.90488523e-05\n  1.60883833e-02 1.38097705e-04 1.03573278e-04 3.45244262e-05\n  1.04954252e-02 2.86552729e-03 2.43397206e-02 1.69169693e-03\n  2.41670976e-04]\n [6.25658214e-01 0.00000000e+00 9.57395881e-04 4.78697941e-04\n  6.22307323e-03 4.78697941e-04 0.00000000e+00 0.00000000e+00\n  9.57395881e-04 5.74437529e-03 4.78697941e-04 0.00000000e+00\n  5.26567735e-03 3.73384394e-02 3.54236476e-02 4.78697941e-04\n  8.61656293e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  1.73288658e-01 3.35088558e-03 7.80277625e-02 7.18046911e-03\n  1.00526568e-02]\n [2.08365813e-01 2.59807741e-04 6.23538578e-03 1.55884642e-02\n  9.09327064e-03 5.71577018e-03 0.00000000e+00 0.00000000e+00\n  3.37750069e-03 1.08599633e-01 1.81865424e-03 0.00000000e+00\n  1.59002334e-01 7.06677064e-02 3.27357762e-02 0.00000000e+00\n  7.95011669e-02 1.81865424e-03 5.19615482e-04 2.59807741e-04\n  8.54767486e-02 2.85788514e-02 1.68095604e-01 1.22109642e-02\n  2.07846193e-03]]\n"
     ]
    }
   ],
   "source": [
    "# compute  Transition Probability\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)\n",
    "\n",
    "# creating t x t transition matrix of tags, t= no of tags\n",
    "# Matrix(i, j) represents P(jth tag after the ith tag)\n",
    " \n",
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]\n",
    " \n",
    "print(tags_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "            NN       RDP        RB       SYM       NEG        QO       QFC  \\\nNN    0.116908  0.000000  0.003591  0.018384  0.015935  0.000347  0.000050   \nRDP   0.430939  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \nRB    0.260944  0.006009  0.001717  0.058369  0.011159  0.005150  0.000000   \nSYM   0.208749  0.009323  0.013626  0.006013  0.000000  0.003751  0.000055   \nNEG   0.002885  0.000000  0.000577  0.007501  0.000577  0.000000  0.000000   \nQO    0.767281  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \nQFC   0.000000  0.000000  0.000000  0.285714  0.000000  0.000000  0.000000   \nINJ   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \nCC    0.270273  0.000000  0.008443  0.017279  0.000491  0.003829  0.000098   \nPSP   0.372791  0.000000  0.007348  0.003509  0.002632  0.003327  0.000110   \nINTF  0.000000  0.000000  0.010033  0.000000  0.000000  0.003344  0.000000   \nVAUX  0.026922  0.000000  0.000804  0.487171  0.000057  0.000057  0.000000   \nNNP   0.068053  0.000000  0.000962  0.067031  0.000271  0.000421  0.000000   \nRP    0.286175  0.000000  0.006174  0.004295  0.019060  0.001342  0.000268   \nQC    0.669246  0.000193  0.000000  0.019923  0.000193  0.000387  0.000000   \nUNK   0.019417  0.000000  0.000000  0.009709  0.038835  0.000000  0.000000   \nPRP   0.319771  0.000089  0.007422  0.003577  0.006885  0.004739  0.000179   \nWQ    0.308880  0.000000  0.003861  0.011583  0.054054  0.000000  0.000000   \nPRPC  0.000000  0.000000  0.000000  0.360000  0.000000  0.000000  0.000000   \nRBC   0.000000  0.000000  0.333333  0.555556  0.000000  0.000000  0.000000   \nJJ    0.547246  0.000064  0.000064  0.013398  0.021063  0.000193  0.000000   \nDEM   0.873947  0.000000  0.000000  0.001358  0.000000  0.001630  0.000000   \nVM    0.033661  0.000035  0.000725  0.182013  0.001899  0.000345  0.000000   \nQF    0.625658  0.000000  0.000957  0.000479  0.006223  0.000479  0.000000   \nNST   0.208366  0.000260  0.006235  0.015588  0.009093  0.005716  0.000000   \n\n           INJ        CC       PSP  ...       UNK       PRP        WQ  \\\nNN    0.000000  0.023332  0.487738  ...  0.000811  0.011203  0.001009   \nRDP   0.000000  0.000000  0.116022  ...  0.000000  0.027624  0.000000   \nRB    0.000000  0.000858  0.006867  ...  0.000858  0.068670  0.001717   \nSYM   0.000110  0.065096  0.023777  ...  0.000110  0.182601  0.001434   \nNEG   0.000000  0.002885  0.000000  ...  0.000000  0.000577  0.000000   \nQO    0.000000  0.027650  0.002304  ...  0.000000  0.004608  0.000000   \nQFC   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \nINJ   0.000000  0.000000  0.000000  ...  0.000000  0.666667  0.000000   \nCC    0.000000  0.012174  0.000098  ...  0.000000  0.187414  0.005301   \nPSP   0.000018  0.001188  0.082107  ...  0.000530  0.046226  0.001225   \nINTF  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \nVAUX  0.000000  0.104414  0.023018  ...  0.000057  0.020952  0.000000   \nNNP   0.000000  0.036762  0.412619  ...  0.000120  0.005350  0.000180   \nRP    0.000000  0.001074  0.028993  ...  0.001074  0.081074  0.000537   \nQC    0.000000  0.005416  0.037718  ...  0.000000  0.000387  0.000000   \nUNK   0.000000  0.000000  0.000000  ...  0.009709  0.000000  0.000000   \nPRP   0.000000  0.002593  0.117500  ...  0.000805  0.078870  0.002146   \nWQ    0.000000  0.003861  0.030888  ...  0.000000  0.092664  0.000000   \nPRPC  0.000000  0.000000  0.000000  ...  0.000000  0.640000  0.000000   \nRBC   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \nJJ    0.000000  0.012045  0.000000  ...  0.000000  0.002641  0.000386   \nDEM   0.000000  0.000000  0.000000  ...  0.000000  0.014127  0.000000   \nVM    0.000000  0.140963  0.141447  ...  0.000069  0.016088  0.000138   \nQF    0.000000  0.000957  0.005744  ...  0.000479  0.008617  0.000000   \nNST   0.000000  0.003378  0.108600  ...  0.000000  0.079501  0.001819   \n\n          PRPC       RBC        JJ       DEM        VM        QF       NST  \nNN    0.000099  0.000066  0.037977  0.003624  0.194020  0.003723  0.004170  \nRDP   0.000000  0.000000  0.093923  0.016575  0.160221  0.005525  0.005525  \nRB    0.000000  0.000000  0.109871  0.033476  0.146781  0.012017  0.004292  \nSYM   0.000221  0.000000  0.063827  0.056766  0.007668  0.007613  0.006013  \nNEG   0.000000  0.000000  0.006924  0.000577  0.956722  0.000000  0.000000  \nQO    0.000000  0.000000  0.050691  0.009217  0.002304  0.002304  0.066820  \nQFC   0.000000  0.000000  0.000000  0.000000  0.000000  0.642857  0.000000  \nINJ   0.000000  0.000000  0.000000  0.000000  0.333333  0.000000  0.000000  \nCC    0.000393  0.000000  0.106028  0.046436  0.006185  0.014824  0.005989  \nPSP   0.000311  0.000165  0.111115  0.020509  0.112852  0.016707  0.048749  \nINTF  0.000000  0.000000  0.675585  0.000000  0.003344  0.270903  0.000000  \nVAUX  0.000115  0.000000  0.006027  0.002985  0.009471  0.001033  0.000172  \nNNP   0.000000  0.000060  0.012414  0.002284  0.014669  0.000782  0.000481  \nRP    0.000000  0.000268  0.136376  0.030336  0.168054  0.030336  0.014497  \nQC    0.000000  0.000000  0.120503  0.002128  0.015861  0.007544  0.000387  \nUNK   0.000000  0.000000  0.029126  0.000000  0.873786  0.000000  0.009709  \nPRP   0.000894  0.000000  0.096754  0.026022  0.121792  0.014486  0.045158  \nWQ    0.000000  0.000000  0.046332  0.019305  0.351351  0.000000  0.003861  \nPRPC  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \nRBC   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \nJJ    0.000064  0.000000  0.039356  0.002770  0.295266  0.003543  0.001675  \nDEM   0.000272  0.000000  0.049171  0.000000  0.000000  0.008422  0.022005  \nVM    0.000104  0.000035  0.010495  0.002866  0.024340  0.001692  0.000242  \nQF    0.000000  0.000000  0.173289  0.003351  0.078028  0.007180  0.010053  \nNST   0.000520  0.000260  0.085477  0.028579  0.168096  0.012211  0.002078  \n\n[25 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NN</th>\n      <th>RDP</th>\n      <th>RB</th>\n      <th>SYM</th>\n      <th>NEG</th>\n      <th>QO</th>\n      <th>QFC</th>\n      <th>INJ</th>\n      <th>CC</th>\n      <th>PSP</th>\n      <th>...</th>\n      <th>UNK</th>\n      <th>PRP</th>\n      <th>WQ</th>\n      <th>PRPC</th>\n      <th>RBC</th>\n      <th>JJ</th>\n      <th>DEM</th>\n      <th>VM</th>\n      <th>QF</th>\n      <th>NST</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>NN</th>\n      <td>0.116908</td>\n      <td>0.000000</td>\n      <td>0.003591</td>\n      <td>0.018384</td>\n      <td>0.015935</td>\n      <td>0.000347</td>\n      <td>0.000050</td>\n      <td>0.000000</td>\n      <td>0.023332</td>\n      <td>0.487738</td>\n      <td>...</td>\n      <td>0.000811</td>\n      <td>0.011203</td>\n      <td>0.001009</td>\n      <td>0.000099</td>\n      <td>0.000066</td>\n      <td>0.037977</td>\n      <td>0.003624</td>\n      <td>0.194020</td>\n      <td>0.003723</td>\n      <td>0.004170</td>\n    </tr>\n    <tr>\n      <th>RDP</th>\n      <td>0.430939</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.116022</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.027624</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.093923</td>\n      <td>0.016575</td>\n      <td>0.160221</td>\n      <td>0.005525</td>\n      <td>0.005525</td>\n    </tr>\n    <tr>\n      <th>RB</th>\n      <td>0.260944</td>\n      <td>0.006009</td>\n      <td>0.001717</td>\n      <td>0.058369</td>\n      <td>0.011159</td>\n      <td>0.005150</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000858</td>\n      <td>0.006867</td>\n      <td>...</td>\n      <td>0.000858</td>\n      <td>0.068670</td>\n      <td>0.001717</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.109871</td>\n      <td>0.033476</td>\n      <td>0.146781</td>\n      <td>0.012017</td>\n      <td>0.004292</td>\n    </tr>\n    <tr>\n      <th>SYM</th>\n      <td>0.208749</td>\n      <td>0.009323</td>\n      <td>0.013626</td>\n      <td>0.006013</td>\n      <td>0.000000</td>\n      <td>0.003751</td>\n      <td>0.000055</td>\n      <td>0.000110</td>\n      <td>0.065096</td>\n      <td>0.023777</td>\n      <td>...</td>\n      <td>0.000110</td>\n      <td>0.182601</td>\n      <td>0.001434</td>\n      <td>0.000221</td>\n      <td>0.000000</td>\n      <td>0.063827</td>\n      <td>0.056766</td>\n      <td>0.007668</td>\n      <td>0.007613</td>\n      <td>0.006013</td>\n    </tr>\n    <tr>\n      <th>NEG</th>\n      <td>0.002885</td>\n      <td>0.000000</td>\n      <td>0.000577</td>\n      <td>0.007501</td>\n      <td>0.000577</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002885</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000577</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.006924</td>\n      <td>0.000577</td>\n      <td>0.956722</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>QO</th>\n      <td>0.767281</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.027650</td>\n      <td>0.002304</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.004608</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.050691</td>\n      <td>0.009217</td>\n      <td>0.002304</td>\n      <td>0.002304</td>\n      <td>0.066820</td>\n    </tr>\n    <tr>\n      <th>QFC</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.285714</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.642857</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>INJ</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.666667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>CC</th>\n      <td>0.270273</td>\n      <td>0.000000</td>\n      <td>0.008443</td>\n      <td>0.017279</td>\n      <td>0.000491</td>\n      <td>0.003829</td>\n      <td>0.000098</td>\n      <td>0.000000</td>\n      <td>0.012174</td>\n      <td>0.000098</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.187414</td>\n      <td>0.005301</td>\n      <td>0.000393</td>\n      <td>0.000000</td>\n      <td>0.106028</td>\n      <td>0.046436</td>\n      <td>0.006185</td>\n      <td>0.014824</td>\n      <td>0.005989</td>\n    </tr>\n    <tr>\n      <th>PSP</th>\n      <td>0.372791</td>\n      <td>0.000000</td>\n      <td>0.007348</td>\n      <td>0.003509</td>\n      <td>0.002632</td>\n      <td>0.003327</td>\n      <td>0.000110</td>\n      <td>0.000018</td>\n      <td>0.001188</td>\n      <td>0.082107</td>\n      <td>...</td>\n      <td>0.000530</td>\n      <td>0.046226</td>\n      <td>0.001225</td>\n      <td>0.000311</td>\n      <td>0.000165</td>\n      <td>0.111115</td>\n      <td>0.020509</td>\n      <td>0.112852</td>\n      <td>0.016707</td>\n      <td>0.048749</td>\n    </tr>\n    <tr>\n      <th>INTF</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.010033</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.003344</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.675585</td>\n      <td>0.000000</td>\n      <td>0.003344</td>\n      <td>0.270903</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>VAUX</th>\n      <td>0.026922</td>\n      <td>0.000000</td>\n      <td>0.000804</td>\n      <td>0.487171</td>\n      <td>0.000057</td>\n      <td>0.000057</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.104414</td>\n      <td>0.023018</td>\n      <td>...</td>\n      <td>0.000057</td>\n      <td>0.020952</td>\n      <td>0.000000</td>\n      <td>0.000115</td>\n      <td>0.000000</td>\n      <td>0.006027</td>\n      <td>0.002985</td>\n      <td>0.009471</td>\n      <td>0.001033</td>\n      <td>0.000172</td>\n    </tr>\n    <tr>\n      <th>NNP</th>\n      <td>0.068053</td>\n      <td>0.000000</td>\n      <td>0.000962</td>\n      <td>0.067031</td>\n      <td>0.000271</td>\n      <td>0.000421</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.036762</td>\n      <td>0.412619</td>\n      <td>...</td>\n      <td>0.000120</td>\n      <td>0.005350</td>\n      <td>0.000180</td>\n      <td>0.000000</td>\n      <td>0.000060</td>\n      <td>0.012414</td>\n      <td>0.002284</td>\n      <td>0.014669</td>\n      <td>0.000782</td>\n      <td>0.000481</td>\n    </tr>\n    <tr>\n      <th>RP</th>\n      <td>0.286175</td>\n      <td>0.000000</td>\n      <td>0.006174</td>\n      <td>0.004295</td>\n      <td>0.019060</td>\n      <td>0.001342</td>\n      <td>0.000268</td>\n      <td>0.000000</td>\n      <td>0.001074</td>\n      <td>0.028993</td>\n      <td>...</td>\n      <td>0.001074</td>\n      <td>0.081074</td>\n      <td>0.000537</td>\n      <td>0.000000</td>\n      <td>0.000268</td>\n      <td>0.136376</td>\n      <td>0.030336</td>\n      <td>0.168054</td>\n      <td>0.030336</td>\n      <td>0.014497</td>\n    </tr>\n    <tr>\n      <th>QC</th>\n      <td>0.669246</td>\n      <td>0.000193</td>\n      <td>0.000000</td>\n      <td>0.019923</td>\n      <td>0.000193</td>\n      <td>0.000387</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005416</td>\n      <td>0.037718</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000387</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.120503</td>\n      <td>0.002128</td>\n      <td>0.015861</td>\n      <td>0.007544</td>\n      <td>0.000387</td>\n    </tr>\n    <tr>\n      <th>UNK</th>\n      <td>0.019417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.009709</td>\n      <td>0.038835</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.009709</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.029126</td>\n      <td>0.000000</td>\n      <td>0.873786</td>\n      <td>0.000000</td>\n      <td>0.009709</td>\n    </tr>\n    <tr>\n      <th>PRP</th>\n      <td>0.319771</td>\n      <td>0.000089</td>\n      <td>0.007422</td>\n      <td>0.003577</td>\n      <td>0.006885</td>\n      <td>0.004739</td>\n      <td>0.000179</td>\n      <td>0.000000</td>\n      <td>0.002593</td>\n      <td>0.117500</td>\n      <td>...</td>\n      <td>0.000805</td>\n      <td>0.078870</td>\n      <td>0.002146</td>\n      <td>0.000894</td>\n      <td>0.000000</td>\n      <td>0.096754</td>\n      <td>0.026022</td>\n      <td>0.121792</td>\n      <td>0.014486</td>\n      <td>0.045158</td>\n    </tr>\n    <tr>\n      <th>WQ</th>\n      <td>0.308880</td>\n      <td>0.000000</td>\n      <td>0.003861</td>\n      <td>0.011583</td>\n      <td>0.054054</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.003861</td>\n      <td>0.030888</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.092664</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.046332</td>\n      <td>0.019305</td>\n      <td>0.351351</td>\n      <td>0.000000</td>\n      <td>0.003861</td>\n    </tr>\n    <tr>\n      <th>PRPC</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.360000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.640000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>RBC</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>0.555556</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>JJ</th>\n      <td>0.547246</td>\n      <td>0.000064</td>\n      <td>0.000064</td>\n      <td>0.013398</td>\n      <td>0.021063</td>\n      <td>0.000193</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.012045</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.002641</td>\n      <td>0.000386</td>\n      <td>0.000064</td>\n      <td>0.000000</td>\n      <td>0.039356</td>\n      <td>0.002770</td>\n      <td>0.295266</td>\n      <td>0.003543</td>\n      <td>0.001675</td>\n    </tr>\n    <tr>\n      <th>DEM</th>\n      <td>0.873947</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.001358</td>\n      <td>0.000000</td>\n      <td>0.001630</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.014127</td>\n      <td>0.000000</td>\n      <td>0.000272</td>\n      <td>0.000000</td>\n      <td>0.049171</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.008422</td>\n      <td>0.022005</td>\n    </tr>\n    <tr>\n      <th>VM</th>\n      <td>0.033661</td>\n      <td>0.000035</td>\n      <td>0.000725</td>\n      <td>0.182013</td>\n      <td>0.001899</td>\n      <td>0.000345</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.140963</td>\n      <td>0.141447</td>\n      <td>...</td>\n      <td>0.000069</td>\n      <td>0.016088</td>\n      <td>0.000138</td>\n      <td>0.000104</td>\n      <td>0.000035</td>\n      <td>0.010495</td>\n      <td>0.002866</td>\n      <td>0.024340</td>\n      <td>0.001692</td>\n      <td>0.000242</td>\n    </tr>\n    <tr>\n      <th>QF</th>\n      <td>0.625658</td>\n      <td>0.000000</td>\n      <td>0.000957</td>\n      <td>0.000479</td>\n      <td>0.006223</td>\n      <td>0.000479</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000957</td>\n      <td>0.005744</td>\n      <td>...</td>\n      <td>0.000479</td>\n      <td>0.008617</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.173289</td>\n      <td>0.003351</td>\n      <td>0.078028</td>\n      <td>0.007180</td>\n      <td>0.010053</td>\n    </tr>\n    <tr>\n      <th>NST</th>\n      <td>0.208366</td>\n      <td>0.000260</td>\n      <td>0.006235</td>\n      <td>0.015588</td>\n      <td>0.009093</td>\n      <td>0.005716</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.003378</td>\n      <td>0.108600</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.079501</td>\n      <td>0.001819</td>\n      <td>0.000520</td>\n      <td>0.000260</td>\n      <td>0.085477</td>\n      <td>0.028579</td>\n      <td>0.168096</td>\n      <td>0.012211</td>\n      <td>0.002078</td>\n    </tr>\n  </tbody>\n</table>\n<p>25 rows × 25 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "#the table is same as the transition table shown in section 3 of article\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))\n",
    "display(tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = list(set([pair[1] for pair in train_tagged_words]))\n",
    "\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    global T    \n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['NNP', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                 \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "             \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('इराक', 'NNP'), ('के', 'PSP'), ('विदेश', 'NN'), ('मंत्री', 'NNP'), ('ने', 'PSP'), ('अमरीका', 'NNP'), ('के', 'PSP'), ('उस', 'DEM'), ('प्रस्ताव', 'NN'), ('का', 'PSP'), ('मजाक', 'NN'), ('उड़ाया', 'VM'), ('है', 'VAUX'), (',', 'SYM'), ('जिसमें', 'PRP'), ('अमरीका', 'NNP'), ('ने', 'PSP'), ('संयुक्त', 'JJ'), ('राष्ट्र', 'NN'), ('के', 'PSP'), ('प्रतिबंधों', 'NN'), ('को', 'PSP'), ('इराकी', 'JJ'), ('नागरिकों', 'NN'), ('के', 'PSP'), ('लिए', 'PSP'), ('', 'SYM'), ('कम', 'QF'), ('हानिकारक', 'JJ'), ('बनाने', 'VM'), ('के', 'PSP'), ('लिए', 'PSP'), ('कहा', 'VM'), ('है', 'VAUX'), ('।', 'SYM')]\n"
     ]
    }
   ],
   "source": [
    "txt = 'इराक के विदेश मंत्री ने अमरीका के उस प्रस्ताव का मजाक उड़ाया है , जिसमें अमरीका ने संयुक्त राष्ट्र के प्रतिबंधों को इराकी नागरिकों के लिए  कम हानिकारक बनाने के लिए कहा है ।'\n",
    "txt = txt.split(\" \")\n",
    "print(Viterbi(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "random.seed(1234)      #define a random seed to get same sentences when run multiple times\n",
    " \n",
    "# choose random 10 numbers\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(10)]\n",
    " \n",
    "# list of 10 sents on which we test the model\n",
    "test_run = [test_set[i] for i in rndom]\n",
    " \n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    " \n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['हुसैन', 'को', 'हवाई', 'अड्डे', 'के', 'आव्रजन', 'क्षेत्र', 'में', 'रोक', 'रखा', 'है', 'और', 'उसे', 'अभी', 'गिरफ्तार', 'नहीं', 'किया', 'गया', 'है', '।', 'मुशर्रफ', 'ने', 'कहा', 'कि', 'अगर', 'मुस्लिम', 'देश', 'या', 'भारत', 'इराक', 'में', 'अपनी', 'सेना', 'भेजते', 'हैं', 'तो', 'पाकिस्तान', 'भी', 'पीछे', 'नहीं', 'रहेगा', '।', 'उन्होंने', 'कहा', 'कि', 'अमेरिका', 'पाकिस्तान', 'के', 'उसके', 'पड़ोसी', 'मुल्कों', 'के', 'साथ', 'बेहतर', 'रिश्ते', 'की', 'वकालत', 'करता', 'रहा', 'है', '।', 'सरकार', 'उन्हें', 'जाल', 'और', 'नौकाएं', 'उपलब्ध', 'कराने', 'के', 'लिए', 'तुरंत', 'कदम', 'उठा', 'रही', 'है', '।', 'इसके', 'लिए', '१०१', 'रुपये', 'और', '५१', 'रुपये', 'भुगतान', 'करना', 'होगा', '।', 'शनिवार', 'को', 'नई', 'दिल्ली', 'में', 'पार्टी', 'की', 'एक', 'बैठक', 'में', 'उन्होंने', 'कहा', 'कि', 'केंद्र', 'की', 'सत्तारूढ़', 'यूपीए', 'सरकार', 'का', 'यह', 'प्रस्ताव', 'इस', 'बात', 'को', 'दर्शाता', 'है', 'कि', 'देश', 'में', 'सुरक्षा', 'की', 'स्थिति', 'कितनी', 'दयनीय', 'है', '?', 'राज्यसभा', 'में', 'प्रश्नकाल', 'के', 'दौरान', 'टी.', 'टी.', 'वी.', 'दिनकरन', 'द्वारा', 'पूछे', 'गये', 'सवाल', 'के', 'जवाब', 'में', 'मुखर्जी', 'ने', 'कहा', 'कि', 'वायुसेना', 'में', 'पायलेटों', 'को', 'मिलने', 'वाली', 'सुविधाएं', 'बेहद', 'सीमित', 'हैं', 'जबकि', 'कार्य', 'जटिल', 'है', '।', 'इससे', 'पहले', 'राव', 'के', 'परिजनों', 'ने', 'पितृ', 'यज्ञ', 'किया', '।', 'जनशिकायतों', 'की', 'सुनवाई', 'को', 'नए', 'लोकपाल', 'विधेयक', 'में', 'सबसे', 'ज्यादा', 'तरजीह', 'दी', 'जाएगी', '।', 'उसके', 'मुताबिक', 'खंडित', 'जनादेश', 'सेकुलर', 'पार्टियों', 'के', 'बीच', 'छिड़ी', 'एक', '-', 'दूसरे', 'को', 'नीचा', 'दिखाने', 'की', 'जंग', 'का', 'नतीजा', 'है', '।']\n"
     ]
    }
   ],
   "source": [
    "print(test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time taken in seconds:  585.578507900238\nViterbi Algorithm Accuracy:  94.58128078817734\n"
     ]
    }
   ],
   "source": [
    "#Here We will only test 10 sentences to check the accuracy\n",
    "#as testing the whole training set takes huge amount of time\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    " \n",
    "print(\"Time taken in seconds: \", difference)\n",
    " \n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    " \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}